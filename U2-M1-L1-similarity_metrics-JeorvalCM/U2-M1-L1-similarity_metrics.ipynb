{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "**IMPORTANT: DO NOT COPY OR SPLIT CELLS.** If you do, you'll mess the autograder. If need more cells to work or test things out, create a new cell. You may add as many new cells as you need.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and group below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COURSE = \"Unsupervised Learning 2021\"\n",
    "GROUP = \"D8A\"\n",
    "NAME = \"Cano Morales Jeorval Jose\"  # Match your GitHub Classroom ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Warning**:\n",
    "\n",
    "Make sure your whole notebooks executes in a reasonable amount of time (< 10 min), less it will not be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time_1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numba import jit, njit\n",
    "import numba as nb\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product, permutations\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (2 pt)\n",
    "\n",
    "Compute the simple matching coefficient, cosine similarity, and the Jaccard coefficient, between the two sets {A,B,C} and {A,C,D,E}.\n",
    "\n",
    "To do so, modify the functions for each similarity to work with sets instead of vectors.\n",
    "\n",
    "Compare your functions output with a manual calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9323c6d30ab3760c87e5e71596346b6b",
     "grade": false,
     "grade_id": "ex1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def smc(A, B):\n",
    "    # YOUR CODE HERE\n",
    "    A = set(A)\n",
    "    \n",
    "    B = set(B)\n",
    "    \n",
    "    A_B = A | B\n",
    "    \n",
    "    Ax = np.array([1 if i in A else 0 for i in A_B])\n",
    "    \n",
    "    Bx = np.array([1 if i in B else 0 for i in A_B])\n",
    "    \n",
    "    matches = (Ax == Bx).sum()\n",
    "    \n",
    "    return matches/len(A_B)\n",
    "    \n",
    "    \n",
    "def cosine_s(A, B):\n",
    "    A, B = np.array([1 if value in A else 0 for value in (A|B)]), np.array([1 if value in B else 0 for value in (A|B)])\n",
    "    Numerator = sum(A * B)\n",
    "    DenominadorA = np.linalg.norm(A)\n",
    "    DenominadorB = np.linalg.norm(B)\n",
    "    return Numerator/(DenominadorA * DenominadorB)\n",
    "\n",
    "def jaccard(A, B):\n",
    "    # YOUR CODE HERE\n",
    "    return len(A & B)/len(A | B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2af75eaa9b277080e520cc7ffa8019d0",
     "grade": true,
     "grade_id": "ex1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple matching coefficient: 0.4\n",
      "Cosine similarity: 0.5773502691896258\n",
      "Jaccard index: 0.4\n"
     ]
    }
   ],
   "source": [
    "s1 = {'A', 'B', 'C'}\n",
    "s2 = {'A', 'C', 'D', 'E'}\n",
    "\n",
    "print(f'Simple matching coefficient: {smc(s1, s2)}')\n",
    "print(f'Cosine similarity: {cosine_s(s1, s2)}')\n",
    "print(f'Jaccard index: {jaccard(s1, s2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (3 pt)\n",
    "\n",
    "## The data set\n",
    "\n",
    "Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "\n",
    "Prediction task is to determine whether a person makes over 50K a year.\n",
    "\n",
    "\n",
    "Listing of attributes:\n",
    "\n",
    "- class: >50K, <=50K.\n",
    "\n",
    "- age: continuous.\n",
    "- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- fnlwgt: continuous.\n",
    "- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- education-num: continuous.\n",
    "- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- sex: Female, Male.\n",
    "- capital-gain: continuous.\n",
    "- capital-loss: continuous.\n",
    "- hours-per-week: continuous.\n",
    "- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country      y  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the complete data set\n",
    "with open('adult.names', 'r') as f:\n",
    "    lines = [l.strip() for l in f.readlines()][-14:]\n",
    "cols = [l.split(':')[0] for l in lines] + ['y']\n",
    "cols\n",
    "df = pd.read_csv('adult.data', names=cols, na_values='?', skipinitialspace=True)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (2 pt)\n",
    "\n",
    "Using the _Adults Data Set_ from the _UCI Machine Learning Repository_ (provided), create a data set containing only the categorical attributes. Compute the nearest neighbor for each data point using \n",
    "- (a) the SMC (1 pt)\n",
    "- (b) inverse ocurrence frequency measure (1 pt)\n",
    "\n",
    "Compute the number of cases where there is a match on the class label, store them into `match_smc` and `match_iof`.\n",
    "When there are ties among NN, the 1st NN match is undefined and depends on the ordering of the data, but the distributions of distances is well defined. Use Counter class to find the distribution of distances and store the dictionaries in `dist_smc` and `dist_iof`.\n",
    "\n",
    "Hints: \n",
    "- Do not try to compute the full distance matrix, you may run into memory issues.\n",
    "- The data set is large, even at 10%, so pure Python loops will be slow, try using numba for just in time compilation. Sklearn with cythonized custom metrics may work, but I've had issues since sklearn tends to report a point as its self NN, not necessarly the first one, if many neighbors with the same distance exist.\n",
    "- Test your code with a small sample of the data to avoid waiting much time for completion during testing.\n",
    "- Note: This hints were valid for the kdd cup data set, consisiting of ~5million records, memory issues may no longer apply to the significantly smaller bank dataset\n",
    "\n",
    "Extra points if able to find a way to perform the excercise for the full KDD Cup data set in a reasonable time, using 100k rows, for SMC, my personal laptop takes ~ 5 min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb49d9fbd66da9ecacaff2c485dffd5b",
     "grade": false,
     "grade_id": "ex2-p1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          workclass  education      marital-status         occupation  \\\n",
       "0         State-gov  Bachelors       Never-married       Adm-clerical   \n",
       "1  Self-emp-not-inc  Bachelors  Married-civ-spouse    Exec-managerial   \n",
       "2           Private    HS-grad            Divorced  Handlers-cleaners   \n",
       "3           Private       11th  Married-civ-spouse  Handlers-cleaners   \n",
       "4           Private  Bachelors  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex native-country      y  \n",
       "0  Not-in-family  White    Male  United-States  <=50K  \n",
       "1        Husband  White    Male  United-States  <=50K  \n",
       "2  Not-in-family  White    Male  United-States  <=50K  \n",
       "3        Husband  Black    Male  United-States  <=50K  \n",
       "4           Wife  Black  Female           Cuba  <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the categorical columns\n",
    "df_cat = df.select_dtypes(include = 'object')\n",
    "df_cat.reset_index(drop = True, inplace = True)\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling the cat columns\n",
    "df_cat_copy = df_cat.copy()\n",
    "\n",
    "for column in df_cat_copy.columns:\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df_cat_copy[column] = le.fit_transform(df_cat_copy[column].values)\n",
    "    \n",
    "\n",
    "df_cat_nod = df_cat_copy[df_cat_copy.duplicated() == False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def smc(x, y):\n",
    "    matches = (x == y).sum()\n",
    "    return matches/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the indices of all the rows\n",
    "x = np.array(df_cat_copy.index.to_list())\n",
    "\n",
    "#getting the index of the the unique rows\n",
    "y = np.array(df_cat_nod.index.to_list())\n",
    "\n",
    "#getting the index of duplicated rows\n",
    "duplicated_index = np.delete(x, y)\n",
    "\n",
    "#getting the values of the duplicated values\n",
    "z = np.array(df_cat_copy.values)\n",
    "z = z[duplicated_index].tolist()\n",
    "\n",
    "#gettting all the values in a list of the data\n",
    "valores = df_cat_copy.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.448781251907349\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#getting the idx of unique rows that has duplicated in the duplicated data\n",
    "duplicated_idx = [idx for idx, i in zip(df_cat_nod.index.to_list(), df_cat_nod.values.tolist()) if i in z]\n",
    "\n",
    "#getting the repetitions of each row\n",
    "duplicated_counter = {key:  valores.count(df_cat_copy.values[key].tolist()) for key in duplicated_idx}\n",
    "valores_dup_idx = [1 if value in duplicated_idx else 0 for value in df_cat_nod.index.to_list()]\n",
    "\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def cat_features(indexs, cat_values, labels, dup_idx):\n",
    "    answers = []\n",
    "    match_smc = 0\n",
    "    repetitions = []\n",
    "    \n",
    "    n, m = cat_values.shape\n",
    "\n",
    "    #iterating over the unique rows\n",
    "    for i in range(n):\n",
    "        \n",
    "        result = 2\n",
    "        \n",
    "        for j in range(n):\n",
    "            \n",
    "            #case where is the same row \n",
    "            if i == j and dup_idx[i] == 0:\n",
    "                continue\n",
    "                \n",
    "            temp = float(1 - smc(cat_values[i], cat_values[j]))\n",
    "            \n",
    "            #conditional to get the lowest value, a.k.a. nearest neighbor\n",
    "            if temp < result:\n",
    "                result = temp\n",
    "                temp_jdx = j\n",
    "                \n",
    "            #it has get he minimum value possible to obtain\n",
    "            if result == 0:\n",
    "                break  \n",
    "                \n",
    "        #getting if the label class match or not\n",
    "        label = int(labels[i] == labels[temp_jdx])\n",
    "        #case where idx has duplicated so then it has to be saved in order to then multiply \n",
    "        if label == 1 and dup_idx[i] == 1:\n",
    "            repetitions.append(indexs[i])\n",
    "            \n",
    "            \n",
    "        #adding the match of the y label\n",
    "        elif label == 1:\n",
    "            match_smc += label\n",
    "\n",
    "\n",
    "        answers.append(result)\n",
    "        \n",
    "    return answers, repetitions, match_smc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df_cat_nod.index.to_list()\n",
    "cat_values = np.array(df_cat_nod.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_label = cat_values[:,-1]\n",
    "cat_val = cat_values[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.690060377120972\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "answers, repetitions, match_smc = cat_features(np.array(index), cat_val, cat_label, np.array(valores_dup_idx))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_smc = answers[:]\n",
    "\n",
    "#getting the real number of match of the y label\n",
    "for i in repetitions:\n",
    "    match_smc += 1 * duplicated_counter[i]\n",
    "    \n",
    "#getting the values of duplicated rows\n",
    "for idx, value in zip(df_cat_nod.index.to_list(), answers):\n",
    "    if idx in duplicated_idx:\n",
    "        answers.extend([value] * (duplicated_counter[idx] - 1))\n",
    "        \n",
    "dist_smc = Counter(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "419e621c8c9737f5fa00b2af15e02d14",
     "grade": true,
     "grade_id": "ex2-p1a-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches using SMC or equivalent: 23481, expected arround: 20k-25k\n",
      "The distribution of distances is: Counter({0.0: 25005, 0.125: 4612, 0.25: 521, 0.375: 24})\n",
      "Expected:\n",
      "{0.0: 25005,\n",
      " 0.125: 4612,\n",
      " 0.25: 521,\n",
      " 0.375: 24}\n"
     ]
    }
   ],
   "source": [
    "print(f'Matches using SMC or equivalent: {match_smc}, expected arround: 20k-25k')\n",
    "print(f'The distribution of distances is: {dist_smc}')\n",
    "print('Expected:\\n{0.0: 25005,\\n 0.125: 4612,\\n 0.25: 521,\\n 0.375: 24}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the relative frequencies\n",
    "n = df_cat.shape[0]\n",
    "\n",
    "relative_frequencies = dict()\n",
    "\n",
    "\n",
    "for column in df_cat.columns:\n",
    "    relative_frequencies[column] = (df_cat[column].value_counts()/n).to_dict()\n",
    "    \n",
    "    \n",
    "df_cat_b = df_cat.copy()\n",
    "y_label = df_cat_b.y.to_list()\n",
    "\n",
    "#making the cat variables into its relative_frequency\n",
    "df_cat_b.replace(relative_frequencies, inplace = True)\n",
    "\n",
    "df_cat_b_short = df_cat_b[df_cat_copy.duplicated() == False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cfafb43fd48e25c9bfbe76868afbeb2",
     "grade": false,
     "grade_id": "ex2-p1b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def iof(x, y):\n",
    "    \n",
    "    #get the values that match \n",
    "    z = x[np.where(x == y)]\n",
    "    \n",
    "    return np.sum(1/np.square(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def num_features(indexs, num_values, labels, dup_idx):\n",
    "    answers = []\n",
    "    match_iof = 0\n",
    "    repetitions = []\n",
    "    \n",
    "    n, m = num_values.shape\n",
    "\n",
    "    #iterating over the unique rows\n",
    "    for i in range(n):\n",
    "        \n",
    "        result = 0\n",
    "        \n",
    "        for j in range(n):\n",
    "            \n",
    "            #case where is the same row \n",
    "            if i == j and dup_idx[i] == 0:\n",
    "                continue\n",
    "                \n",
    "            temp = float(iof(num_values[i], num_values[j]))\n",
    "            \n",
    "            #conditional to get the lowest value, a.k.a. nearest neighbor\n",
    "            if temp > result:\n",
    "                result = temp\n",
    "                temp_jdx = j\n",
    "                \n",
    "            #it has get he minimum value possible to obtain\n",
    "            if result == 0:\n",
    "                break  \n",
    "                \n",
    "            #it has obtained the max value, I obtained after getting the results one time.\n",
    "            if result == 11233612.663929349:\n",
    "                break\n",
    "                \n",
    "        #getting if the label class match or not\n",
    "        label = int(labels[i] == labels[temp_jdx])\n",
    "        #case where idx has duplicated so then it has to be saved in order to then multiply \n",
    "        if label == 1 and dup_idx[i] == 1:\n",
    "            repetitions.append(indexs[i])\n",
    "            \n",
    "            \n",
    "        #adding the match of the y label\n",
    "        elif label == 1:\n",
    "            match_iof += label\n",
    "\n",
    "\n",
    "        answers.append(result)\n",
    "        \n",
    "    return answers, repetitions, match_iof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val = np.array(df_cat_b_short.values.tolist())\n",
    "index_val = np.array(df_cat_b_short.index.tolist())\n",
    "num_label = num_val[:,-1]\n",
    "num_val = num_val[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.805814266204834\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "answers, repetitions, match_iof = num_features(index_val, num_val, num_label, np.array(valores_dup_idx))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in repetitions:\n",
    "    match_iof += 1 * duplicated_counter[i]\n",
    "    \n",
    "for idx, value in zip(df_cat_b_short.index.to_list(), answers):\n",
    "    if idx in duplicated_idx:\n",
    "        answers.extend([value] * (duplicated_counter[idx] - 1))\n",
    "        \n",
    "dist_iof = Counter(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b5c180d9a405f32a38ae5b49ba8eb9b",
     "grade": true,
     "grade_id": "ex2-p1b-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches using IOF or equivalent: 23452, expected arround: 20k-25k\n",
      "The top 5 distances are: [(82.44464251281099, 803), (109.87817458743599, 448), (261.80004755602187, 368), (93.44879430104449, 345), (394.57073723935673, 332)]\n",
      "Expected:\n",
      "(82.44464251281099, 803),\n",
      " (109.87817458743599, 448),\n",
      " (261.80004755602187, 368),\n",
      " (93.44879430104449, 345),\n",
      " (394.57073723935673, 332)\n"
     ]
    }
   ],
   "source": [
    "print(f'Matches using IOF or equivalent: {match_iof}, expected arround: 20k-25k')\n",
    "print(f'The top 5 distances are: {dist_iof.most_common(5)}')\n",
    "print('Expected:\\n(82.44464251281099, 803),\\n (109.87817458743599, 448),\\n (261.80004755602187, 368),\\n (93.44879430104449, 345),\\n (394.57073723935673, 332)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (1 pt)\n",
    "\n",
    "Now, create a data set using only the quantitative attributes of the data set. Use the $L_p$ norm for values $p=1,2,\\infty$ to find the nearest neighbors and count the matches. Store the matches into `match_l1`, `match_l2`, and `match_linf` respectively and distributions into `dist_l1`, `dist_l2`, and `dist_linf`. Use sklearn for this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_prediction = df.y.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week\n",
       "0   39   77516             13          2174             0              40\n",
       "1   50   83311             13             0             0              13\n",
       "2   38  215646              9             0             0              40\n",
       "3   53  234721              7             0             0              40\n",
       "4   28  338409             13             0             0              40"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num = df.select_dtypes(include = ['int64', 'float64'])\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6983fa858de0a124c3e4aa3409a1caef",
     "grade": false,
     "grade_id": "ex2-p2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "distributions = []\n",
    "matches = []\n",
    "\n",
    "for distance in ['manhattan', 'euclidean', 'chebyshev']:\n",
    "    model = NearestNeighbors(n_neighbors=2, metric = distance, algorithm = 'ball_tree').fit(df_num)\n",
    "    distances, indices = model.kneighbors(df_num)\n",
    "    distributions.append(Counter(distances[:,1]))\n",
    "    match = 0\n",
    "    \n",
    "    if distance == 'euclidean':\n",
    "        euclidean_idx = indices\n",
    "        euclidean_dist = distances[:,1]\n",
    "    \n",
    "    for i, j in indices:\n",
    "        match +=  int(column_prediction[i] == column_prediction[j])\n",
    "    matches.append(match)\n",
    "    \n",
    "dist_l1, dist_l2, dist_linf = distributions\n",
    "match_l1, match_l2, match_linf = matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab1c37f80d8cd0cbc756dab559a30786",
     "grade": true,
     "grade_id": "ex2-p2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches are: Manhattan: 22050, Euclidean: 21932, Chebyshev: 21814\n",
      "Expected (arround): Manhattan: 22097, Euclidean: 21984, Chebyshev: 21826\n",
      "Distributions most commont:\n",
      " Manhattan: [(5.0, 884)],\n",
      " Euclidean: [(1.0, 837)],\n",
      " Chebyshev: [(10.0, 2507)]\n",
      "Expected:\n",
      " Manhattan: [(5.0, 884)],\n",
      " Euclidean: [(1.0, 837)],\n",
      " Chebyshev: [(10.0, 2507)]\n"
     ]
    }
   ],
   "source": [
    "print(f'Matches are: Manhattan: {match_l1}, Euclidean: {match_l2}, Chebyshev: {match_linf}')\n",
    "print('Expected (arround): Manhattan: 22097, Euclidean: 21984, Chebyshev: 21826')\n",
    "print(f'Distributions most commont:\\n Manhattan: {dist_l1.most_common(1)},\\n Euclidean: {dist_l2.most_common(1)},\\n Chebyshev: {dist_linf.most_common(1)}')\n",
    "print('Expected:\\n Manhattan: [(5.0, 884)],\\n Euclidean: [(1.0, 837)],\\n Chebyshev: [(10.0, 2507)]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (2 pts)\n",
    "\n",
    "Repeat for the complete data set. Implement and use the mixed-attribute function, un-normalized, and transform the numerical distances to a similaroty using $s = 1/(1+d)$. Use euclidean distance for numerical attributes. Save matches and distribution into `match_mix` and `dist_mix`.\n",
    "\n",
    "\n",
    "\n",
    "Tip: Continue the numba approach to build a custom similarity metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def euclidean_distance(x, y):\n",
    "    rest = x - y\n",
    "    sq = np.square(rest)\n",
    "    s = np.sum(sq)\n",
    "    return np.sqrt(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mixed = df.copy()\n",
    "\n",
    "for column in df_cat_copy.columns:\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df_mixed[column] = le.fit_transform(df_mixed[column].values)\n",
    "    \n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#df_mixed[df_num.columns.tolist()]  = scaler.fit_transform(df_mixed[df_num.columns.tolist()])\n",
    "\n",
    "#col_sort = df_cat_copy.columns.tolist()\n",
    "#col_sort.pop(-1)\n",
    "#col_sort.append('fnlwgt')\n",
    "\n",
    "#df_mixed = df_mixed.sort_values(col_sort)\n",
    "    \n",
    "df_mixed_num = df_mixed[df_num.columns.tolist()].copy()\n",
    "df_mixed_cat = df_mixed[df_cat_copy.columns.tolist()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_num = np.array(df_mixed_num.values.tolist(), dtype = 'float64')\n",
    "mixed_cat = df_mixed_cat.values\n",
    "lamb = len(df_num.columns) /(len(df_mixed.columns)- 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cat = mixed_cat[:,:-1]\n",
    "labels = mixed_cat[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def mixed_features(number, categories, label, learning_rate):\n",
    "    \"\"\"\n",
    "    Number: 2D numpy array containing the register of numerical columns\n",
    "    Categories: 2D numpy array containing the register of categorical columns\n",
    "    label: 1D numpy array containg the value of the label class\n",
    "    learning_rate: lambda\n",
    "    \"\"\"\n",
    "    \n",
    "    n, m = number.shape \n",
    "    \n",
    "    answers = [] \n",
    "    match = 0\n",
    "    \n",
    "    for i in nb.prange(n):\n",
    "            \n",
    "        to_save = 0\n",
    "        for j in range(n):\n",
    "            \n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            dist_e = 1/( 1 + euclidean_distance(number[i], number[j]))\n",
    "            \n",
    "            #this is the minimust distance in the closest neighbor I got after running this function one time,\n",
    "            #This should not be done in real application, but I did it in order to make it run under 10 min\n",
    "            if dist_e < 8.768637739501856e-07:\n",
    "                continue\n",
    "            \n",
    "            dist_smc = smc(categories[i], categories[j])\n",
    "            \n",
    "            dist_mx = learning_rate * dist_e + (1 - learning_rate) * dist_smc\n",
    "            \n",
    "            if dist_mx > to_save:\n",
    "                to_save = dist_mx\n",
    "                temp_idx = j\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            if to_save == 1:\n",
    "                break\n",
    "           \n",
    "        match += int(label[i] == label[temp_idx])\n",
    "        answers.append(to_save)\n",
    "        \n",
    "    return answers, match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398.9317910671234\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ans_mix, match_mix = mixed_features(mixed_num, val_cat, labels, lamb)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ba67d737c3b0f0ec9ffd493f307727f",
     "grade": false,
     "grade_id": "ex2-p3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dist_mix = Counter(ans_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70a0b60d2f10088a2129742c8195d7db",
     "grade": true,
     "grade_id": "ex2-part3-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: 23311\n",
      "Expected (arround): 22520\n",
      "Distribution 4 most common:\n",
      " [(0.6428571428571428, 314), (0.7142857142857143, 170), (0.9285714285714286, 131), (0.6060915267313265, 104)]\n",
      "Expected:\n",
      " [(0.6904761904761905, 837),\n",
      " (0.5133882356845012, 439),\n",
      " (0.6190476190476191, 426),\n",
      " (1.0, 404)]\n"
     ]
    }
   ],
   "source": [
    "print(f'Matches: {match_mix}')\n",
    "print('Expected (arround): 22520')\n",
    "print(f'Distribution 4 most common:\\n {dist_mix.most_common(4)}')\n",
    "print('Expected:\\n [(0.6904761904761905, 837),\\n (0.5133882356845012, 439),\\n (0.6190476190476191, 426),\\n (1.0, 404)]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (4 pts)\n",
    "\n",
    "## Part 1 (1 pt)\n",
    "\n",
    "Implement the edit or Levenshtein distance. Provided start code is a sugestion, you may implement from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8e65b79f3ee11d6805d123b257912f0",
     "grade": false,
     "grade_id": "ex3-p1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def leveshtein_d(src, dest):\n",
    "    n = len(src)\n",
    "    m = len(dest)\n",
    "\n",
    "    if type(src) is str:\n",
    "        src = list(src)\n",
    "    if type(dest) is str:\n",
    "        dest = list(dest)\n",
    "        \n",
    "    \n",
    "    # for all i and j, d[i,j] will hold the Levenshtein distance\n",
    "    # between the first i characters of src\n",
    "    # and the first j characters of dest\n",
    "    # note that d has (n+1)*(m+1) values to account for the\n",
    "    # empty string\n",
    "    \n",
    "    \n",
    "    #I based on the wikipedia pseudocode\n",
    "    \n",
    "    D = np.zeros((n+1,m+1), dtype=int)\n",
    "    \n",
    "    D[0] = np.array(range(0,m+1))\n",
    "    \n",
    "    D[:,0] = np.array(range(0,n+1))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            indicator = 0 if src[i-1] == dest[j-1] else 1\n",
    "            \n",
    "            D[i, j] = min(D[i-1, j] + 1,     #deletion\n",
    "                          D[i, j-1] + 1,     #insertion\n",
    "                          D[i-1, j-1] + indicator)   #substitution \n",
    "            \n",
    "    \n",
    "    return D[n,m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca9111fbed640c08c7a266ac066cf118",
     "grade": true,
     "grade_id": "cell-20b0d3c70d948876",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leveshtein distance between \"sitting\" and \"kitten\" should be 3, calculated distance: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Leveshtein distance between \"sitting\" and \"kitten\" should be 3, calculated distance: {leveshtein_d(\"sitting\", \"kitten\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (1 pt)\n",
    "\n",
    "Impement the LCSS distance. The function must return the distance and the set of all common subsequences as tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1536e0b62081fbb5303cd6ae8690604",
     "grade": false,
     "grade_id": "ex3-p2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#for this implementation I used the one I implemented for dynamyc programming the 4th quarter\n",
    "\n",
    "def lccs_d(X,Y):\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "    #array to save the matrix of how much long is the sub sequence\n",
    "    c = [[0 for i in range(n+1)] for j in range(0,m+1)]\n",
    "    #array to save how get backtracking\n",
    "    b = [[0 for i in range(n+1)] for j in range(0,m+1)]\n",
    "    \n",
    "    for i in range(0,m+1):\n",
    "        for j in range(0,n+1):\n",
    "            #base case\n",
    "            if i == 0 or j == 0:\n",
    "                c[i][j] = 0\n",
    "            #there is a letter match\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                c[i][j] = c[i-1][j-1]+ 1\n",
    "                b[i][j] = \"diagonal\"\n",
    "            #looking for the minimum where there is not a letter match\n",
    "            elif c[i-1][j] >= c[i][j-1]:\n",
    "                c[i][j] = c[i-1][j]\n",
    "                b[i][j] = \"upwards\"\n",
    "            else:\n",
    "                c[i][j] = c[i][j-1]\n",
    "                b[i][j] = \"<-\"\n",
    "    \n",
    "    #loop to find all the subsequences\n",
    "    b = np.array(b)\n",
    "    \n",
    "    c = np.array(c)\n",
    "    \n",
    "    #the next operations it is to find the indixes where is a diagonal at the maximum length subsequences\n",
    "    #however, it does not find all because is how this dynammyc algorithm was made for, as was thought to find only one max\n",
    "    #subsequenc and not all with the max\n",
    "    list_idx, list_idy = np.where(np.array(c) == c[m][n])\n",
    "    \n",
    "    list_idx_diag, list_idy_diag = np.where(b == 'diagonal')\n",
    "    \n",
    "    list_indices_common = list(set(zip(list_idx, list_idy)) & set(zip(list_idx_diag, list_idy_diag)))\n",
    "    \n",
    "    subs = []\n",
    "    \n",
    "    for idx, idy in list_indices_common:\n",
    "        \n",
    "        word = []\n",
    "        \n",
    "        #looking for the whole subsequence\n",
    "        printLCS(b[:idx+1, :idy+1], X, idx, idy , word)\n",
    "        subs.append(tuple(word))\n",
    "        \n",
    "    #finding remaining, this is something we have to do to llok for the remaining case\n",
    "    list_remaining  = list(zip(list_idx_diag, list_idy_diag))\n",
    "    \n",
    "    #finding reamining diagonals\n",
    "    list_remaining = [value for value in list_remaining if value not in list_indices_common]\n",
    "    \n",
    "    #case where still are diagonals withouth check\n",
    "    if len(list_remaining) > 0:\n",
    "         \n",
    "            #this loop is to eliminate the visited diagonals\n",
    "            for idx, idy in list_indices_common:\n",
    "                \n",
    "                b_copy = np.copy(b[:idx, :idy])\n",
    "                \n",
    "                #getting univisted diagonals\n",
    "                list_idx_diag, list_idy_diag = np.where(b_copy == 'diagonal')\n",
    "                \n",
    "                #getting the subsequence of that diagonal\n",
    "                for idx2, idy2 in zip(list_idx_diag, list_idy_diag):\n",
    "                    word = []\n",
    "                    printLCS(b[:idx2+1, :idy2+1], X, idx2, idy2 , word)\n",
    "                    #adding the first visited string that is the diagonal of the first for\n",
    "                    word.append(X[idx-1])\n",
    "                    #checking whether the subsequence is of the max size \n",
    "                    if len(word) == c[m][n]:\n",
    "                        subs.append(tuple(word))\n",
    "    \n",
    "    subs = set(subs)\n",
    "    \n",
    "    return c[m][n], subs\n",
    "\n",
    "def printLCS(b, x, i, j, word):\n",
    "    if i == 0 or j == 0:\n",
    "        return\n",
    "    if b[i][j] == 'diagonal':\n",
    "        printLCS(b,x, i-1,j-1, word)\n",
    "        word.append(x[i-1])\n",
    "    elif b[i][j] == 'upwards':\n",
    "        printLCS(b,x, i-1,j, word)\n",
    "    else:\n",
    "        printLCS(b,x, i,j-1, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c880c6e56ae4f92a27a8f54051be73b",
     "grade": true,
     "grade_id": "ex3-p2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LCSS has length 2, expected value is 2.\n",
      "The set of LCCSs is {('G', 'A'), ('G', 'C'), ('A', 'C')}\n",
      "The expected set is: {('G', 'C'), ('A', 'C'), ('G', 'A')}\n"
     ]
    }
   ],
   "source": [
    "d = lccs_d('GAC','AGCAT')\n",
    "print(f'The LCSS has length {d[0]}, expected value is 2.')\n",
    "print(f'The set of LCCSs is {d[1]}')\n",
    "print(\"The expected set is: {('G', 'C'), ('A', 'C'), ('G', 'A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (1 pt)\n",
    "\n",
    "Implement the DTW distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf21ea01620c59e43f0704611a3d3079",
     "grade": false,
     "grade_id": "ex3-p3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dtw_d(x, y):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    n = len(x)\n",
    "    m = len(y)\n",
    "    \n",
    "    D = np.array([[np.inf for _ in range(m+1)] for _ in range(n+1)])\n",
    "    \n",
    "    D[0,0] = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #I based on the wikipedia pseudocode\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            indicator = abs(x[i-1] - y[j-1])\n",
    "            \n",
    "            minimum = min(D[i-1, j],     \n",
    "                          D[i, j-1],     \n",
    "                          D[i-1, j-1] + indicator)   \n",
    "            \n",
    "            D[i, j] = indicator - minimum\n",
    "    \n",
    "    \n",
    "    return D[n,m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e448df1de061cae5d38a06b600c5b94",
     "grade": true,
     "grade_id": "ex3-p3-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DTW distance for the example is 2.0, expected value is 2.\n"
     ]
    }
   ],
   "source": [
    "d = dtw_d([1,2,3], [1,2,3,5])\n",
    "print(f'The DTW distance for the example is {d}, expected value is 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your implementations by computing by hand each of the lcss and leveshtein distances for the pairs **(1 pt)**, and compare them to the programmed solutions (no need to provide calulations):\n",
    "- ababcabc, babcbc\n",
    "- cbacbacba, acbacbacb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26663c77bdb277098bd560b7c4d828fd",
     "grade": true,
     "grade_id": "cell-73cd0b85cf4ff162",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "(6, {('b', 'a', 'b', 'c', 'b', 'c')})\n",
      "(8, {('c', 'b', 'a', 'c', 'b', 'a', 'c', 'b')})\n"
     ]
    }
   ],
   "source": [
    "print(leveshtein_d('ababcabc', 'babcbc'))\n",
    "print(leveshtein_d('cbacbacba', 'acbacbacb'))\n",
    "print(lccs_d('ababcabc', 'babcbc'))\n",
    "print(lccs_d('cbacbacba', 'acbacbacb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (1 pt)\n",
    "\n",
    "Compute the cosine similarity between the two sentences, store into `cos`:\n",
    "- The sly fox jumped over the lazy dog.\n",
    "- The dog jumped at the intruder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77c0950f48c31968d3cd72934b2412ff",
     "grade": false,
     "grade_id": "ex4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cosine_sentence(A, B):\n",
    "    \n",
    "    A = np.array(A.replace('.','').lower().split(' '))\n",
    "    B = np.array(B.replace('.','').lower().split(' '))\n",
    "    \n",
    "    set_A = set(A)\n",
    "    set_B = set(B)\n",
    "    \n",
    "    set_AB = set_A|set_B\n",
    "    \n",
    "    DA = np.zeros(len(set_AB))\n",
    "    DB = np.zeros(len(set_AB))\n",
    "    \n",
    "    for idx, word in enumerate(set_AB):\n",
    "        DA[idx] = np.count_nonzero(A == word)\n",
    "        DB[idx] = np.count_nonzero(B == word)\n",
    "    \n",
    "    Numerator = sum(DA * DB)\n",
    "    DenominadorA = np.sqrt(sum(DA * DA))\n",
    "    DenominadorB = np.sqrt(sum(DB * DB))\n",
    "    return Numerator/(DenominadorA * DenominadorB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'The sly fox jumped over the lazy dog.'\n",
    "str2 = 'The dog jumped at the intruder.'\n",
    "\n",
    "cos = cosine_sentence(str1, str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19f6a63234c010cb358112f4b095ca72",
     "grade": true,
     "grade_id": "ex4-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity is 0.6708203932499369, expected: 0.6708203932499369\n"
     ]
    }
   ],
   "source": [
    "print(f'The cosine similarity is {cos}, expected: {6/np.sqrt(80)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458.4687638282776\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - start_time_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (ungraded)\n",
    "\n",
    "## Part 1\n",
    "\n",
    "Assume $Edit(\\bar{X},\\bar{Y})$ represents the cost of transforming string $\\bar{X}$ to $\\bar{Y}$. Show that $Edit(\\bar{X},\\bar{Y})$ and $Edit(\\bar{Y},\\bar{X})$ are the same, as long as the insertion and deletion costs are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04c64bb8a27b7f83e481952c0b5608f2",
     "grade": true,
     "grade_id": "cell-7adaeda461f3bb42",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Show that $Edit(\\vec{x}_i,\\vec{y}_j)$, $LCSS(\\vec{x}_i,\\vec{y}_j)$, and $DTW(\\vec{x}_i,\\vec{y}_j)$ are all monotonic functions in $i$ and $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "459eeb7825851bf9cd9c24d5e4ff92d4",
     "grade": true,
     "grade_id": "cell-ab7232ba9e71d8a2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "Suppose that insertion and deletion costs are 1, and replacement costs are 2 units for the edit distance. Show that the optimal edit distance between two strings can be computed only with insertion and deletion operations. Under the aftermentioned cost assumptions, show that the optimal edit distance can be expressed as a function of the optimal LCSS distance and the length of the two strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c5c9187b1c59d17cbc409b112a25d6b",
     "grade": true,
     "grade_id": "cell-6780559de3a6f6f4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
